{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmedshuvo969/quora-insincere-questions-classification/blob/master/cosine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZmPnrSaaAc4",
        "colab_type": "text"
      },
      "source": [
        "# Data Loading & analysis\n",
        "import the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqaeL5CTNcFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import re\n",
        "import os\n",
        "import nltk\n",
        "import string\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCtCjrFIZpTK",
        "colab_type": "text"
      },
      "source": [
        "Uploading file\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGt8RK8RyIPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train=pd.read_csv('/content/train (1).csv')\n",
        "test=pd.read_csv('test.csv')\n",
        "test_pred=pd.read_csv('sample_submission.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9BzBQlZz_QL",
        "colab_type": "text"
      },
      "source": [
        "The distribution of target variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrEx2-Mnz1tL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.countplot(train['target'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkDpjQK00MRc",
        "colab_type": "text"
      },
      "source": [
        "Percentage of sincere and insincere questions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in391sYe0JUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len_data = len(train['target'])\n",
        "count_sin = 0\n",
        "for i in range(len_data):\n",
        "    if train['target'][i] == 1:\n",
        "        count_sin += 1\n",
        "count_insin = len_data - count_sin\n",
        "len_text_data = len(test['question_text'])\n",
        "\n",
        "print('percent of sincere is : ', (count_sin/len_data)*100)\n",
        "print('percent of insincere is : ', (count_insin/len_data)*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQnBcYte0amR",
        "colab_type": "text"
      },
      "source": [
        "# Pre-processing\n",
        "Check missing or nan value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO3BK0jI0UMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.isnull().sum() #absent of missing value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rS20x6iULRyE",
        "colab_type": "text"
      },
      "source": [
        "Removing stopwords, cleaning punctuation/html tag/, stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2__maV21Qz7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for train corpus\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer \n",
        "\n",
        "corpus = []\n",
        "for i in range(0, len_data):\n",
        "    review = re.sub('[^a-zA-Z]', ' ', train['question_text'][i])\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    ps = PorterStemmer()\n",
        "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
        "    review = ' '.join(review)\n",
        "    corpus.append(review)\n",
        "\n",
        "y_train = []    \n",
        "for i in range(0, len_data):\n",
        "    y_train.append(train['target'][i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hnRumy53bJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for testing corpus\n",
        "test_corpus = []\n",
        "for i in range(0, len_text_data):\n",
        "    review = re.sub('[^a-zA-Z]', ' ', test['question_text'][i])\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    ps = PorterStemmer()\n",
        "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
        "    review = ' '.join(review)\n",
        "    test_corpus.append(review)\n",
        "\n",
        "\n",
        "y_test = []    \n",
        "for i in range(0, len_text_data):\n",
        "    y_test.append(test_pred['prediction'][i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1sNs-1wLhbq",
        "colab_type": "text"
      },
      "source": [
        "separte sincere and insincere "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNUiCkh_kPzb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PosSet = []\n",
        "NegSet = []\n",
        "TestSet = []\n",
        "k = 0\n",
        "for i in corpus:\n",
        "    m = i.split(\" \")\n",
        "    if y_train[k] == 1: \n",
        "        for j in m:\n",
        "            PosSet.append(j)\n",
        "    else:\n",
        "        for j in m:\n",
        "            NegSet.append(j)\n",
        "    k = k+1\n",
        "\n",
        "\n",
        "PosSet = ' '.join(PosSet)\n",
        "NegSet = ' '.join(NegSet)\n",
        "\n",
        "\n",
        "\n",
        "doc = [PosSet, NegSet]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yN0FnkhsL5Ea",
        "colab_type": "text"
      },
      "source": [
        "TF-IDF vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqEUXJ3EkT-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "matrix1 = vectorizer.fit_transform(doc)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU3qqy0A9IG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matrix2 = vectorizer.transform(test_corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZAF517gMYeD",
        "colab_type": "text"
      },
      "source": [
        "# Relationship using Cosine Similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltUe4NDs-X-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "rel = cosine_similarity(matrix2, matrix1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8pVY-N7HSXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = []\n",
        "\n",
        "for i in range(0, len_text_data):\n",
        " \n",
        "  if rel[i][0]>rel[i][1]:\n",
        "      y_pred.append(1)\n",
        "  else:\n",
        "      y_pred.append(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npGeTGk2b0nN",
        "colab_type": "text"
      },
      "source": [
        "Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6njSLyTkkuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c0xGLvLb4xM",
        "colab_type": "text"
      },
      "source": [
        "Accuracy, Precision, Recall, F1 Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0b05jYJKpzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "# accuracy: (tp + tn) / (p + n)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "print('Recall: %f' % recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print('F1 score: %f' % f1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}